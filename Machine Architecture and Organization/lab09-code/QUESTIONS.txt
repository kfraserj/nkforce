			   __________________

			    LAB 09 QUESTIONS
			   __________________


- Name: Ju-Yu, Chou Fu
- NetID: chouf001

Answer the questions below according to the lab specification. Write
your answers directly in this text file and submit it to complete the
lab.


Compiling and Timing
====================

  IMPORTANT: Use the provided Makefile to compile as in
  ,----
  | > make
  | gcc -Wall -g -Og -c superscalar_main.c
  | gcc -Wall -g -Og -c superscalar_funcs.c
  | gcc -Wall -g -Og -o superscalar_main superscalar_main.o superscalar_funcs.o
  `----
  The compilation uses `-Og' (debug level optimization) which is
  necessary to stop the compiler from modifying some loops.

  This will produce the `superscalar_main' program which has the
  following usage:
  ,----
  | > ./superscalar_main
  | usage: ./superscalar_main <ALG> <MULT> <EXP>
  |   <MULT> and <ALG> are integers, iterates for MULT * 2^{EXP} iterations
  |   <ALG> is one of
  | 	  add1_sep : add 1 times in loop
  | 	  add2_sep : add 2 times in same loop; separate destinations
  | 	  add3_sep : add 3 times in same loop; separate destinations
  | 	 add2_same : add 2 times in same loop; same destinations
  | 	  mul1_sep : multiply 1 times in loop
  | 	  mul2_sep : multiply 2 times in same loop; separate destinations
  | 	  mul3_sep : multiply 3 times in same loop; separate destinations
  | 	 mul2_same : multiply 2 times in same loop; same destinations
  |    add_and_mul_sep : add and multiply in the same loop; separate destinations
  |   add_and_mul_same : add and multiply in the same loop; same destination
  |   add_then_mul_sep : add and multiply in different loops; separate destinations
  |  add_then_mul_same : add and multiply in different loops; same destinations
  `----

  Experiment with algorithm `add1_sep' and parameters `MULT' and `EXP'
  which control the number of iterations run. Experiment until you get a
  run time of about 1 second such as MULT=18 and EXP=27 on Vole.
  ,----
  | vole-01> time ./superscalar_main add1_sep 18 27
  | add1_sep for 18 * 2^{27} = 2415919104 iterations... complete
  |
  | real    0m1.071s
  | user    0m1.040s
  | sys     0m0.008s
  `----


PROBLEM 1: Addition
===================

(A) add1_sep / add2_sep / add3_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Examine the source code in `superscalar_funcs.c' for the following
  algorithms.
  - add1_sep : add 1 times in loop
  - add2_sep : add 2 times in same loop; separate destinations
  - add3_sep : add 3 times in same loop; separate destinations
  Note that each does some additions in a loop. Time each of these WITH
  THE SAME MULT/EXP parameters and show your timings. Describe how the
  timings compare and speculate on why.

  Note that all of these involve incrementing a counter (`i++') so the
  number of additions is one greater than the algorithm name suggests.

	add1_sep 18 27: real	0m0.671s
	add2_sep 18 27: real	0m0.644s
  add3_sep 18 27: real	0m0.947s



add2_sep has two instructions that add twice in a loop to different locations. Even though
it has two adding instructions, but the superscalar can execute these two instructions
at the same time. Hence, in general, add2_sep should uses the same time as add1_sep. But, in
this case, "strange timing" involves in this problem.

in add3_sep, it has three adding instructions. Hence, it takes longer to complete than the
other two functions.



(B) add2_sep / add2_same
~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the source code of the two algorithms below.
  - add1_sep : add 1 times in loop
  - add2_sep : add 2 times in same loop; separate destinations
  - add2_same : add 2 times in same loop; same destinations
  Note that the only difference between the add2_X algorithms is that
  the destination for the results.

  Compare timings for these and speculate on the reasons for any
  unexpected results.

	add1_sep  18 27: real	0m0.755s
	add2_sep  18 27: real	0m0.743s
  add2_same 18 27: real	0m1.312s

	for add2_same, the second instruction cannot be executed until the first instruction
	is executed since the function adds twice to same location, retA. Hence, this explains
	why add2_same takes nearly twice as long as add2_sep does.


PROBLEM 2: Multiplication
=========================

(A) add1_sep / mul1_sep
~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add1_sep : add 1 times in loop
  - mul1_sep : multiply 1 times in loop
  Time them on the same parameters and speculate on the timing
  differences.

add1_sep  18 27: real	0m0.649s
mul1_sep  18 27: real 0m1.897s

these two functions both only have one instruction. however, multiplication takes
3 clock cycles to complete while addition only takes 1 clock cycle. This explains
why mul1_sep takes nearly triple as long as add1_sep does

(B) mul1_sep / mul2_sep / mul3_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - mul1_sep : multiply 1 times in loop
  - mul2_sep : multiply 2 times in same loop; separate destinations
  - mul3_sep : multiply 3 times in same loop; separate destinations
  Time them on the same parameters and speculate on the timing
  differences.

mul1_sep  18 27: real 0m1.869s
mul2_sep  18 27: real 0m1.917s
mul3_sep  18 27: real 0m1.867s

pipelining plays a role here. even though mul2_sep and mul3_sep have more intructions
than mul1_sep, pipelinging makes the process of multiplication more efficient.
This explans why these three results are similar. However, in general, mul2_sep and
mul3_sep should take slightly more time.

(C) mul1_sep / mul2_sep / mul2_same
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - mul1_sep : multiply 1 times in loop
  - mul2_sep : multiply 2 times in same loop; separate destinations
  - mul2_same : multiply 2 times in same loop; same destinations
  Time them on the same parameters and speculate on the timing
  differences.

	mul2_sep  18 27: real 0m1.870s
	mul2_same 18 27: real 0m3.883s

	for mul2_same, the second instruction cannot be executed until the first instruction
	is executed since the function adds twice to the same location, retA. Hence, this explains
	why mul2_same takes nearly twice as long as mul_sep does.

PROBLEM 3: Combined Addition/Multiplication
===========================================

(A) add1_then_mul_sep / add2_and_mul_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add1_then_mul_sep : add and multiply in different loops; separate
    destinations
  - add2_and_mul_sep : add twice and multiply in the same loop; separate
    destinations
  Note that each loop involves incrementing a counter so both of the
  above algorithms should do the same number of operations for N
  iterations:
  -----------------------------------------------
                      loop          total  total
   Algorithm          incr   adds   adds   mults
  -----------------------------------------------
   add1_then_mul_sep  2 * N  1 * N  3 * N  N
   add2_and_mul_sep_  1 * N  2 * N  3 * N  N
  -----------------------------------------------

  Time these algorithms on the same parameters and speculate on the
  timing differences.

  Compare the timings to your earlier results for add1_sep and mul1_sep.

add1_then_mul_sep 18 27: real	0m2.490s
add2_and_mul_sep  18 27: real	0m1.869s

add1_then_mul_sep has two for-loops where the second loop can't be executed until
the first loop is done.

in add2_and_mul_sep, superscalar plays a role here that executes these two instructions,
retA += del; and retM *= del; simultaneously.

Hence, add1_then_mul_sep takes longer than add2_and_mul_sep

(B) add2_then_mul_sep / add2_and_mul_same
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add_and_mul_sep : add and multiply in the same loop; separate
    destinations
  - add_and_mul_same : add and multiply in the same loop; same
    destination
  Time them on the same parameters and speculate on the timing
  differences.

	add2_and_mul_sep   18 27: real	0m1.868s
	add2_and_mul_same  18 27: real	0m3.242s

	the two instructions, adding and multiplication, in add2_and_mul_sep are working with
	two different locations while add2_and_mul_same's adding and multiplicaiton are working
	with the same locations. The reason why add2_and_mul_same takes longer than add2_and_mul_sep
	is similar to Problem 1B and Problem 2C

  Compare the timings to your earlier results for add1_sep and mul1_sep.

	add1_sep  18 27: real	0m0.649s
	mul1_sep  18 27: real   0m1.897s

	these two functions both only have one instruction. however, multiplication takes
	3 clock cycles to complete while addition only takes 1 clock cycle. This explains
	why mul1_sep takes nearly triple as long as add1_sep does

  Compare the following two algorithms.
  - add1_then_mul_same : add and multiply in different loops; same
    destinations
  - add2_and_mul_same : add twice and multiply in the same loop; same
    destination

		add1_then_mul_same 18 27: real	0m2.559s
		add2_and_mul_same  18 27: real	0m3.242s

		using additions in two for-loops has no difference than adding twice in one for-loop since the destinations are the same.
	        the reason why add2_and_mul_same is slower than add1_then_mul_same is because add2_and_mul_same has branch prediction.

  As before the operation count is the same but in this case the
  destination for adds/multiplies is the same.

  Time these algorithms on the same parameters and speculate on the
  timing differences. Compare to the results from part A where the
  destinations are distinct memory/register locations.
